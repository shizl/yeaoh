# Small robots.txt
# More information about this file can be found at
# <a href="http://www.robotstxt.org/">http://www.robotstxt.org/</a>

# In case your drupal site is in a subdirectory of your web root  (e.g. /drupal)
# add the name of this directory before the / (slash) below
# example:  Disallow: /drupal/aggregator

# to stop a polite robot indexing an example dir
# add a line like:  user-agent: polite-bot 
# and:  Disallow: /example-dir/

# Paths (clean URLs)
User-agent: *
Crawl-Delay: 10
Disallow: /aggregator
Disallow: /tracker
Disallow: /comment/reply
Disallow: /node/add
Disallow: /search/
Disallow: /book/print
Disallow: /logout
Disallow: /user/register
Disallow: /user/password
Disallow: /user/login

# Paths (no clean URLs)
User-agent: *
Crawl-Delay: 10
Disallow: /?q=aggregator
Disallow: /?q=tracker
Disallow: /?q=comment/reply
Disallow: /?q=node/add
Disallow: /?q=user/register
Disallow: /?q=user/password
Disallow: /?q=user/login
Disallow: /?q=search/
Disallow: /?q=book/print

# Blocks user "track" pages
Disallow: /*/track$
# Blocks common URL parameters created by the Views module on tables
Disallow: /*sort=
Disallow: /*size=